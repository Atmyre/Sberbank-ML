{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import scipy\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разреженные признаки\n",
    "\n",
    "**Примеры** источников разреженных признаков:\n",
    "\n",
    "* Категориальные признаки \n",
    "* Текст\n",
    "\n",
    "## Категориальные признаки\n",
    "\n",
    "Категориальные признаки, также могут упоминаться, как факторные или номинальные признаки. \n",
    "\n",
    "**Примеры** категориальных признаков: \n",
    "\n",
    "* пол\n",
    "* страна проживания\n",
    "* номер группы\n",
    "\n",
    "и т.п.\n",
    "\n",
    "Ясно, что для компьютерной обработки вместо \"понятного для человека\" значения (в случае страны — \"Russia\", \"GB\", \"France\" и т.п.) хранят числа. Далее обсудим, как получать подобное вектор-признаки и в каком формате их хранить.\n",
    "\n",
    "Рассмотрим таблицу ```winemag.csv```, которая содержит описания вин."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>Vulkà Bianco</td>\n",
       "      <td>87</td>\n",
       "      <td></td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td></td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>@kerinokeefe</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td></td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>Reserve Late Harvest</td>\n",
       "      <td>87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td></td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td></td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>Vintner's Reserve Wild Child Block</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                                        description  \\\n",
       "0     Italy  Aromas include tropical fruit, broom, brimston...   \n",
       "1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
       "2        US  Tart and snappy, the flavors of lime flesh and...   \n",
       "3        US  Pineapple rind, lemon pith and orange blossom ...   \n",
       "4        US  Much like the regular bottling from 2012, this...   \n",
       "\n",
       "                          designation  points price           province  \\\n",
       "0                        Vulkà Bianco      87        Sicily & Sardinia   \n",
       "1                            Avidagos      87  15.0              Douro   \n",
       "2                                          87  14.0             Oregon   \n",
       "3                Reserve Late Harvest      87  13.0           Michigan   \n",
       "4  Vintner's Reserve Wild Child Block      87  65.0             Oregon   \n",
       "\n",
       "              region_1           region_2         taster_name  \\\n",
       "0                 Etna                          Kerin O’Keefe   \n",
       "1                                                  Roger Voss   \n",
       "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "3  Lake Michigan Shore                     Alexander Peartree   \n",
       "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "\n",
       "  taster_twitter_handle                                              title  \\\n",
       "0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n",
       "1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
       "2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
       "3                        St. Julian 2013 Reserve Late Harvest Riesling ...   \n",
       "4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n",
       "\n",
       "          variety               winery  \n",
       "0     White Blend              Nicosia  \n",
       "1  Portuguese Red  Quinta dos Avidagos  \n",
       "2      Pinot Gris            Rainstorm  \n",
       "3        Riesling           St. Julian  \n",
       "4      Pinot Noir         Sweet Cheeks  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('winemag.csv', index_col=0, na_filter=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таблице 10 столбцов с признаками. Какие из них являются категориальными? \n",
    "\n",
    "Во-первых, это должны быть столбцы содержащие текстовые значения. Следовательно, в качестве кандидатов остаются: ```country```, ```description```, ```designation```, ```province```, ```region_1```, ```region_2```, ```variety``` и ```winery```.\n",
    "\n",
    "Во-вторых, столбцы с небольшим числом уникальных значений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: 44\n",
      "description: 119955\n",
      "designation: 37980\n",
      "province: 426\n",
      "region_1: 1230\n",
      "region_2: 18\n",
      "variety: 708\n",
      "winery: 16757\n"
     ]
    }
   ],
   "source": [
    "for name in ['country', 'description', 'designation', 'province',\n",
    "             'region_1', 'region_2', 'variety', 'winery']:\n",
    "    print('%s: %d'%(name, data[name].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
       "        93,  94,  95,  96,  97,  98,  99, 100])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data[\"points\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, страна-производитель является категориальным признаком.\n",
    "\n",
    "Самым очевидным способом кодирования является - **one-hot-кодирование**: для кодируемого категориального признака создаются $N$ новых признаков, где $N$ - число категорий. Каждый $i$-й новый признак - бинарный характеристический признак $i$-й категории.\n",
    "\n",
    "Например, страна-производитель является категориальным признаком. Воспользуемся [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) и [OneHotEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) для преобразования названий стран в one-hot-вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = data.country\n",
    "countries = LabelEncoder().fit_transform(countries)\n",
    "countries = OneHotEncoder().fit_transform(countries[:, np.newaxis])\n",
    "\n",
    "type(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разреженные матрицы\n",
    "\n",
    "После кодирования мы получили разреженную матрицу признаков. Существует много типов разреженных матриц, каждый из которых предоставляет разные гарантии на операции.\n",
    "\n",
    "* ```scipy.sparse.coo_matrix```\n",
    "* ```scipy.sparse.csc_matrix```\n",
    "* ```scipy.sparse.csr_matrix```\n",
    "* ```scipy.sparse.bsr_matrix```\n",
    "* ```scipy.sparse.lil_matrix```\n",
    "* ```scipy.sparse.dia_matrix```\n",
    "* ```scipy.sparse.dok_matrix```\n",
    "\n",
    "Подробнее про [устройство разреженых матрицы](http://www.netlib.org/utk/people/JackDongarra/etemplates/node372.html)\n",
    "\n",
    "### scipy.sparse.coo_matrix\n",
    "\n",
    "* Используется как хранилище данных\n",
    "* Поддерживает быструю конвертацию в любой формат\n",
    "* Не поддерживает индексацию\n",
    "* Поддерживает ограниченый набор арифметических операций\n",
    "\n",
    "### scipy.sparse.csc_matrix\n",
    "\n",
    "* Хранит данные поколоночно\n",
    "* Быстрое получение значений отдельных колонок\n",
    "\n",
    "### scipy.sparse.csr_matrix\n",
    "\n",
    "* Хранит данные построчно\n",
    "* Быстрое получение значений отдельных строк\n",
    "\n",
    "### scipy.sparse.bsr_matrix\n",
    "\n",
    "* Подходит для разреженных матриц с плотными подматрицами\n",
    "\n",
    "### scipy.sparse.lil_matrix\n",
    "\n",
    "* Подходит для создания разреженных матриц поэлементно\n",
    "* Для последующих матричных операций лучше сконвертировать в ```csr_matrix``` или ```csc_matrix```\n",
    "\n",
    "Библиотека ```scipy.sparse``` содержит методы, позволяющие работать с разреженными матрицами. Подробнее про операции с разрежеными матрицами на сайте [scipy](https://docs.scipy.org/doc/scipy/reference/sparse.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание оценки вин\n",
    "\n",
    "В качестве категориальных признаков возьмём: country, province и variety\n",
    "\n",
    "Попробуем предсказать оценку выставленную винам. Оценки в таблицы варьируются от 80 до 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:40,  5.83s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>0.140869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>province</th>\n",
       "      <td>0.147653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variety</th>\n",
       "      <td>0.145065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country; province</th>\n",
       "      <td>0.148656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country; variety</th>\n",
       "      <td>0.144459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>province; variety</th>\n",
       "      <td>0.153132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country; province; variety</th>\n",
       "      <td>0.156420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy\n",
       "country                     0.140869\n",
       "province                    0.147653\n",
       "variety                     0.145065\n",
       "country; province           0.148656\n",
       "country; variety            0.144459\n",
       "province; variety           0.153132\n",
       "country; province; variety  0.156420"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data.points.values\n",
    "countries = OneHotEncoder().fit_transform(LabelEncoder().\\\n",
    "                                          fit_transform(data.country)[:, np.newaxis])\n",
    "provinces = OneHotEncoder().fit_transform(LabelEncoder().\\\n",
    "                                          fit_transform(data.province)[:, np.newaxis])\n",
    "varieties = OneHotEncoder().fit_transform(LabelEncoder().\\\n",
    "                                          fit_transform(data.variety)[:, np.newaxis])\n",
    "features = [('country', countries), ('province', provinces), ('variety', varieties)]\n",
    "\n",
    "names = []\n",
    "accuracy_scores = []\n",
    "for subset_features in tqdm(itertools.chain(*[list(itertools.combinations(features, n)) \n",
    "                                              for n in range(1, 4)])):\n",
    "    subset_names, subset_features = zip(*subset_features)\n",
    "    names.append('; '.join(subset_names))\n",
    "    \n",
    "    X = scipy.sparse.hstack(subset_features)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33)\n",
    "    \n",
    "    lr = LogisticRegression().fit(X_train, Y_train)\n",
    "    Y_pred = lr.predict(X_test)\n",
    "\n",
    "    accuracy_scores.append(accuracy_score(Y_pred, Y_test))\n",
    "\n",
    "pd.DataFrame({'Accuracy':accuracy_scores}, index=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Извлечение признаков из текстов\n",
    "\n",
    "Перед тем как работать с текстом, его необходимо токенизировать - разбить на отдельные токены. В качестве токенов могут выступать слова, фразы, предложений и т.п. Токенизировать текст можно  помощью регулярных выражений или готовых токенизаторов. \n",
    "\n",
    "После токенизации нужно привести текст к нормальной форме. Речь идет о [стемминге и/или лемматизации](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html) - это схожие процессы, используемые для обработки словоформ.\n",
    "\n",
    "Для работы лемматизации английского текста можно воспользоваться библиотекой [SpaCy]( https://spacy.io/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150930/150930 [1:41:14<00:00, 24.85it/s]  \n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en')\n",
    "description_lemma = [' '.join([token.lemma_ for token in nlp(text)]) \n",
    "                     for text in tqdm(data.description)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this tremendous 100 % varietal wine hail from oakville and be age over three year in oak . juicy red - cherry fruit and a compelling hint of caramel greet the palate , frame by elegant , fine tannin and a subtle minty tone in the background . balanced and rewarding from start to finish , -PRON- have year ahead of -PRON- to develop further nuance . enjoy 2022–2030 .'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_lemma[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words\n",
    "\n",
    "Cоздаем вектор длиной в словарь, для каждого слова считаем количество вхождений в текст и подставляем это число на соответствующую позицию в векторе.\n",
    "\n",
    "Построим модель BOW с помощью [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 26383\n",
      "Top-10 слов: and; the; be; of; with; pron; this; wine; flavor; in\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer().fit(description_lemma)\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "print('Размер словаря: %d'%len(vocabulary))\n",
    "\n",
    "description_count = vectorizer.transform(description_lemma)\n",
    "top_tokens, _ = zip(*sorted(zip(vocabulary, description_count.sum(axis=0).getA1()), \n",
    "                            key=lambda x: x[1], reverse=True)[:10])\n",
    "print('Top-10 слов: %s'%'; '.join(top_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что большая часть из топ-10 слов является не информативными - стоп-словами. Что бы они не участвовали в представление, в конструктор CountVectorizer в качестве параметра можно передать список стоп-слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 26290\n",
      "Top-10 слов: pron; wine; flavor; fruit; finish; cherry; aroma; tannin; dry; acidity\n"
     ]
    }
   ],
   "source": [
    "stop_words = get_stop_words('en')\n",
    "vectorizer = CountVectorizer(stop_words=stop_words).fit(description_lemma)\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "print('Размер словаря: %d'%len(vocabulary))\n",
    "\n",
    "description_count = vectorizer.transform(description_lemma)\n",
    "top_tokens, _ = zip(*sorted(zip(vocabulary, description_count.sum(axis=0).getA1()), \n",
    "                            key=lambda x: x[1], reverse=True)[:10])\n",
    "print('Top-10 слов: %s'%'; '.join(top_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы сжать векторное представление, можно \"отбросить\" редкие слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 16143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<150930x16143 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3750840 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stop_words, min_df=3).fit(description_lemma)\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "print('Размер словаря: %d'%len(vocabulary))\n",
    "\n",
    "description_count = vectorizer.transform(description_lemma)\n",
    "description_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf\n",
    "\n",
    "Cлова, которые редко встречаются в корпусе (во всех рассматриваемых документах этого набора данных), но присутствуют в этом конкретном документе, могут оказаться более важными. Тогда имеет смысл повысить вес более узкотематическим словам, чтобы отделить их от общетематических. Этот подход называется [TF-IDF](https://en.wikipedia.org/wiki/Tf–idf).\n",
    "\n",
    "Значение Tf-Idf для каждого пары документ-слово состоит из двух компонент:\n",
    "* Term frequency — логарифм встречаемости слова в документе\n",
    "\n",
    "$$tf(t, d) = \\log n_{t,d}$$\n",
    "\n",
    "* Inverse Document frequency — логарифм обратной доли документов в которых встретилось данное слово\n",
    "\n",
    "$$idf(t, D) = \\log \\frac{ \\mid D \\mid}{\\mid \\{ d_i \\in D \\mid t \\in d_i \\} \\mid}$$\n",
    "\n",
    "* Tf-Idf — кобминация tf и idf\n",
    "\n",
    "$$ TfIdf(t, d, D) = tf(t, d) * idf(t, D)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 слов: hoed; nonnenberg; consulting; coutinel; congenial; blessing; alderbrook; marriage; charlemagne; 50g\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stop_words).fit(description_lemma)\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "\n",
    "description_tfidf = vectorizer.transform(description_lemma)\n",
    "top_tokens, _ = zip(*sorted(zip(vocabulary, description_count.sum(axis=0).getA1()), \n",
    "                            key=lambda x: x[1], reverse=True)[:10])\n",
    "print('Top-10 слов: %s'%'; '.join(top_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание оценки вин\n",
    "\n",
    "Добавляем к категориальным признакам, признаки извлечённые из описаний сомелье."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BOW</th>\n",
       "      <td>0.385287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfIdf</th>\n",
       "      <td>0.325215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy\n",
       "BOW    0.385287\n",
       "TfIdf  0.325215"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "for description in [description_count, description_tfidf]:\n",
    "\n",
    "    X = scipy.sparse.hstack([countries, provinces, varieties, description])\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33)\n",
    "    \n",
    "    lr = LogisticRegression().fit(X_train, Y_train)\n",
    "    Y_pred = lr.predict(X_test)\n",
    "    \n",
    "    accuracy_scores.append(accuracy_score(Y_pred, Y_test))\n",
    "\n",
    "pd.DataFrame({'Accuracy':accuracy_scores}, index=['BOW', 'TfIdf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25\n",
    "\n",
    "Метод вычисления весов ```Okapi BM25```, который развивает идею Tf-Idf, учитывая длину документов в $tf(t, d)$.\n",
    "\n",
    "$$tf(t, d) = \\frac{(k_1 + 1) * n_{t,d}}{k_1 * (1 - b + b * \\frac{L_d}{L_{ave}}) + n_{t,d}}$$\n",
    "\n",
    "где\n",
    "* $k_1$ и $b$ - свободные коэффициенты, обычно их выбирают как $k_1=2.0$ и $b=0.75$\n",
    "* $L_d$ - длина документа $d$\n",
    "* $L_{ave}$ - средняя длина документа в коллекции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vowpal Wabbit\n",
    "\n",
    "Довольно часто бывает, что данных очень много и обучаться приходится на выборках, которые не помещаются в память. А также, довольно часто хорошее качество можно получить благодаря простым линейным моделям, при условии, что были хорошо отобраны и сгенерированы признаки. \n",
    "\n",
    "Важным достоинством линейных методов является то, что при обучении можно добиться того, что настройка параметров алгоритма (т.е. этап обновления весов) будет производится каждый раз при добавлении нового обьекта. Данные методы машинного обучения в литературе часто также называют Online Machine Learning. При этом не нужно хранить все обьекты одновременно в памяти теперь просто не нужно.\n",
    "\n",
    "На сегодняшний день одной из самых известных реализаций таких методов является пакет [Vowpal Wabbit](https://github.com/JohnLangford/vowpal_wabbit):\n",
    "\n",
    "* Можно обучать только линейные модели. Увеличивать качество методов, можно за счет добавления новых признаков и подгонки функции потерь\n",
    "\n",
    "* Обучающая выборка обрабатывается с помощью стахостического оптимизатора, благодаря чему можно обучаться на выборках, которые не помещаются в память\n",
    "\n",
    "* Можно обрабатывать большое количество признаков за счет их хэширования (так называемый hashing trick), бладаря чему можно обучать модели даже в случаях, когда полный набор весов просто не помещается в памяти\n",
    "\n",
    "* Поддерживается режим активного обучения, при котором обьекты обучающей выборки можно подавать даже с нескольких машин по сети\n",
    "\n",
    "* Обучение может быть распараллелено на несколько машин\n",
    "\n",
    "### Установка\n",
    "\n",
    "* Ubuntu - ```apt-get install vowpal-wabbit```\n",
    "* Mac OS - ```port install vowpal_wabbit```\n",
    "* Windows - скачать установочник [тут](https://github.com/eisber/vowpal_wabbit/releases)\n",
    "\n",
    "### Формат данных\n",
    "\n",
    "Label [weight] |Namespace Feature ... |Namespace ...\n",
    "\n",
    "* ```Label``` - метка класса для задачи классификации или действительное число для задачи регрессии\n",
    "* ```weight``` - вес объекта, по умолчанию у всех 1\n",
    "* ```Namespace``` - все признаки разбиты на области видимости, может использоваться для раздельного использования или создания квадратичных признаков между областями\n",
    "* ```Feature``` - ```string[:value]``` или ```int[:value]``` строки будут хешированы, числа будут использоваться как индекс в векторе признаков. ```value``` по умолчанию равно $1$\n",
    "\n",
    "### Параметры\n",
    "\n",
    "**Hashing trick**\n",
    "\n",
    "Вводится функция $h$, с помощью которой получается индекс для записи значения в вектор признаков объекта.\n",
    "\n",
    "$$h : F \\rightarrow \\{0, \\dots, 2^b - 1\\}$$\n",
    "\n",
    "С помощью ```--b``` можно задавать размер области значений хеш-функции. Чем больше значение ```b```, тем меньше вероятность получить коллизии при хешировании признаков.\n",
    "\n",
    "**Оптимизация**\n",
    "\n",
    "Может использовать ```SGD``` или ```L-BFGS``` (квази-ньютоновский метод второго порядка, подробнее про работу [оптимизации](http://aria42.com/blog/2014/12/understanding-lbfgs))\n",
    "\n",
    "По умолчанию используется ```SGD```. ```L-BFGS``` включается с помощью ```--bfgs```, работает гораздо медленнее и подходит только для выборок небольшого размера. \n",
    "\n",
    "Количество проходов по данным для ```SGD``` задаётся с помощью параметра ```--passes```\n",
    "\n",
    "**Параметры оптимизации**\n",
    "\n",
    "Обновление весов происходит на каждом объекте:\n",
    "<br/>\n",
    "\n",
    "$$w_{t+1} = w_{t} + \\eta_t \\nabla_{w}\\ell(w_{t}, x_{t})$$\n",
    "$$\\eta_t = \\lambda d^k \\left( \\frac{t_0}{t_0 + t} \\right)^p$$\n",
    "\n",
    "где $t$ - номер объекта при обучении, $k$ - номер эпохи. Остальные параметры задаются следующим образом:\n",
    "\n",
    "* $\\lambda$: ```-l```\n",
    "* $d$: ```--decay_learning_rate```\n",
    "* $t_0$: ```--initial_t```\n",
    "* $p$: ```--power_t```\n",
    "\n",
    "**Функция потерь** задаётся через ```--loss_function```\n",
    "\n",
    "**Регуляризация** задаётся через два флага ```--l1``` и ```--l2```\n",
    "\n",
    "**Квадратичные признаки**\n",
    "\n",
    "* ```-q ab``` — создаёт квадратичные признаки, перемножая все признаки из областей видимости, названия которых начинаются на букву __a__ и на букву __b__\n",
    "* ```--ignore a``` — игнорирует все признаки из области видимости, название которой начинается на букву __a__\n",
    "\n",
    "**Режим демона**\n",
    "\n",
    "* ```--daemon``` — запускает __vw__ в режиме сервиса на порту, который можно задать с помощью ```--port```\n",
    "* Позволяет обучать модель и/или применять модель по сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num weight bits = 18\r\n",
      "learning rate = 0.5\r\n",
      "initial_t = 0\r\n",
      "power_t = 0.5\r\n",
      "using no cache\r\n",
      "Reading datafile = \r\n",
      "num sources = 1\r\n",
      "\r\n",
      "\r\n",
      "VW options:\r\n",
      "  --random_seed arg                     seed random number generator\r\n",
      "  --ring_size arg                       size of example ring\r\n",
      "\r\n",
      "Update options:\r\n",
      "  -l [ --learning_rate ] arg            Set learning rate\r\n",
      "  --power_t arg                         t power value\r\n",
      "  --decay_learning_rate arg             Set Decay factor for learning_rate \r\n"
     ]
    }
   ],
   "source": [
    "!vw -h | head -n10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_vw = pd.DataFrame({'class': Y-80, 'description':[' '.join(re.findall(r'\\w+', d)) \n",
    "                                                      for d in description_lemma]})\n",
    "data_train, data_test = train_test_split(data_vw)\n",
    "data_train.to_csv('data.train.vw', sep='|', header=None, index=False)\n",
    "data_test.to_csv('data.test.vw', sep='|', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!vw -d data.train.vw  -f model.vw --loss_function logistic --oaa 21 --quiet --passes 100 -c -k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ```-d``` — откуда брать данны для обучения\n",
    "* ```-f``` — куда сохранять модель\n",
    "* ```--passes``` — максимальное количество проходов по выборке\n",
    "* ```-c``` — создавать файл с кешем, необходимо указывать, если используется ```--passes```\n",
    "* ```-k``` — перед запуском очищать кеш"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!vw -d data.test.vw -i model.vw -r output.csv --loss_function logistic --quiet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ```-i``` — путь до готовой модели\n",
    "* ```-t``` — не обучаться, только вернуть предсказания\n",
    "* ```-p``` — путь до файла для записи предсказаний\n",
    "* ```--quite``` — не выводить никакую информацию в консоль"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
